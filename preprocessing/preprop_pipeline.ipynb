{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avkaz/DeepLearningPetIdentification/blob/preprocess_pipeline/preprop_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook for creating dataset of pets pairs"
      ],
      "metadata": {
        "id": "xx13VecqWTEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main goal is to create a dataset for fine tuning pretrained model.\n",
        "Each row consist of 2 pictures, metadata and label. Label \"1\" is if pictures are of the same pet and \"0\" if pets a different.\n",
        "Result dataset is saved in a json format."
      ],
      "metadata": {
        "id": "mO8-grKfWguI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Utility library"
      ],
      "metadata": {
        "id": "8Puzo3ZdV6KN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5yEKEaHmNW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbafff2-0f07-435d-c5a5-c2f63bc1a7f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "utility.py downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "## 1st -  Download utility.py file from github repository\n",
        "## 2nd - Imports all functions from utility.py\n",
        "\n",
        "import requests\n",
        "\n",
        "# Correct raw URL for the utility.py file\n",
        "url = \"https://raw.githubusercontent.com/avkaz/DeepLearningPetIdentification/main/utility.py\"\n",
        "\n",
        "# Fetch and save the file locally\n",
        "response = requests.get(url)\n",
        "with open(\"utility.py\", \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "\n",
        "import utility\n",
        "print(\"utility.py downloaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining filtering and controlling functions"
      ],
      "metadata": {
        "id": "DdnaSTvkXR88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_metadata_with_images(metadata):\n",
        "    \"\"\"\n",
        "    Filters metadata to include only entries with non-empty 'images' lists.\n",
        "\n",
        "    Args:\n",
        "        metadata (dict): The original metadata dictionary.\n",
        "\n",
        "    Returns:\n",
        "        dict: A filtered metadata dictionary with entries that have images.\n",
        "    \"\"\"\n",
        "    return {key: value for key, value in metadata.items() if value.get(\"images\")}"
      ],
      "metadata": {
        "id": "LU5h3hAcaiIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metadata Verification\n",
        "def verify_metadata(metadata):\n",
        "    \"\"\"\n",
        "    Verifies metadata integrity by checking for missing or inconsistent entries.\n",
        "\n",
        "    Args:\n",
        "        metadata (dict): The metadata dictionary to verify.\n",
        "    \"\"\"\n",
        "    for key, value in metadata.items():\n",
        "        if not isinstance(value, dict) or \"Plemeno\" not in value or \"Barva\" not in value or \"Věk\" not in value or \"Velikost\" not in value or \"images\" not in value:\n",
        "            print(f\"Warning: Incomplete metadata for key {key}: {value}\")"
      ],
      "metadata": {
        "id": "ZcAVyoCJ7trZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_to_list(tensor):\n",
        "    \"\"\"Converts a tensor to a list of pixel values.\"\"\"\n",
        "    return tensor.numpy().tolist()"
      ],
      "metadata": {
        "id": "R0rhibBgXgs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_pet_pairs_to_json(pet_pairs, pet_name, filename=\"pet_pairs.json\"):\n",
        "    \"\"\"Saves the pairs for a specific pet to a JSON file.\"\"\"\n",
        "    try:\n",
        "        with open(filename, 'a') as json_file:  # Open in append mode\n",
        "            json.dump({pet_name: pet_pairs}, json_file, indent=4)\n",
        "            json_file.write(\"\\n\")  # To separate each pet's data\n",
        "        print(f\"Pairs for {pet_name} successfully saved to {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving pairs for {pet_name} to JSON: {e}\")"
      ],
      "metadata": {
        "id": "Y2LV6KgUXi9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining main function"
      ],
      "metadata": {
        "id": "VIu8FIFKXjn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import utility  # Assuming utility contains download_and_preprocess_image function\n",
        "\n",
        "def tensor_to_list(tensor):\n",
        "    \"\"\"Converts a tensor to a list of pixel values.\"\"\"\n",
        "    return tensor.numpy().tolist()\n",
        "\n",
        "def save_pet_pairs_to_json(pet_pairs, pet_name, filename=\"pet_pairs.json\"):\n",
        "    \"\"\"Saves the pairs for a specific pet to a JSON file.\"\"\"\n",
        "    try:\n",
        "        with open(filename, 'a') as json_file:  # Open in append mode\n",
        "            json.dump({pet_name: pet_pairs}, json_file, indent=4)\n",
        "            json_file.write(\"\\n\")  # To separate each pet's data\n",
        "        print(f\"Pairs for {pet_name} successfully saved to {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving pairs for {pet_name} to JSON: {e}\")\n",
        "\n",
        "def preprocess_dataset_random(metadata, target_size=(224, 224), max_same_pet_pairs=2, max_diff_pet_pairs=2, start_from_index=0):\n",
        "    \"\"\"\n",
        "    Preprocesses the dataset to create pairs of images for the same pet and random different pets.\n",
        "    Returns a list of dictionaries containing metadata and image pairs.\n",
        "    The function will start processing from the pet defined by the start_from_index.\n",
        "    Each pet's pairs will be saved incrementally.\n",
        "    \"\"\"\n",
        "    data_pairs = []\n",
        "    pet_pair_count = {key: 0 for key in metadata}  # To track the number of pairs per pet\n",
        "\n",
        "    # Print statement to show the beginning of the preprocessing\n",
        "    print(\"Starting dataset preprocessing...\")\n",
        "\n",
        "    all_keys = list(metadata.keys())\n",
        "\n",
        "    # Starting from the defined index (start_from_index)\n",
        "    all_keys = all_keys[start_from_index:]\n",
        "\n",
        "    # Print the starting point\n",
        "    print(f\"Starting from pet {all_keys[0]} at index {start_from_index}...\")\n",
        "\n",
        "    for idx, key in enumerate(all_keys, start=start_from_index):\n",
        "        entry = metadata[key]\n",
        "        plemeno = entry.get(\"Plemeno\", \"Unknown\")\n",
        "        vek = entry.get(\"Věk\", \"Unknown\")\n",
        "        barva = entry.get(\"Barva\", \"Unknown\")\n",
        "        velikost = entry.get(\"Velikost\", \"Unknown\")\n",
        "        images = entry.get(\"images\", [])\n",
        "\n",
        "        print(f\"Processing pet {key} ({idx + 1}/{len(all_keys) + start_from_index})...\")  # Print current pet number\n",
        "\n",
        "        if len(images) < 2:\n",
        "            print(f\"Skipping pet {key}: Not enough images ({len(images)})\")\n",
        "            continue\n",
        "\n",
        "        same_pet_pair_count = 0\n",
        "        diff_pet_pair_count = 0\n",
        "        pet_data_pairs = []\n",
        "\n",
        "        processed_same_pairs = set()  # To track the same-pet pairs\n",
        "        processed_diff_pairs = set()  # To track the different-pet pairs\n",
        "\n",
        "        # Counter to track duplicate skips\n",
        "        duplicate_skip_count = 0\n",
        "\n",
        "        # First, create same-pet pairs until max_same_pet_pairs is reached\n",
        "        print(f\"Processing same-pet pairs for {key}...\")\n",
        "        while same_pet_pair_count < max_same_pet_pairs:\n",
        "            random.shuffle(images)\n",
        "            for i in range(len(images)):\n",
        "                for j in range(i + 1, len(images)):\n",
        "                    if same_pet_pair_count >= max_same_pet_pairs:\n",
        "                        break\n",
        "\n",
        "                    # Create a unique pair identifier\n",
        "                    pair_id = tuple(sorted([images[i], images[j]]))  # Sorting ensures order doesn't matter\n",
        "\n",
        "                    if pair_id in processed_same_pairs:\n",
        "                        print(f\"Skipping duplicate same-pet pair: {images[i]} and {images[j]}\")\n",
        "                        duplicate_skip_count += 1\n",
        "                        if duplicate_skip_count > 3:\n",
        "                            print(f\"Skipping pet {key} due to too many duplicate skips. Moving to next pet.\")\n",
        "                            break  # Move to the next pet if too many duplicates are found\n",
        "                        continue  # Skip if the pair has already been processed\n",
        "\n",
        "                    try:\n",
        "                        print(f\"Processing same-pet pair: {images[i]} and {images[j]} for {key}\")\n",
        "                        image1 = utility.download_and_preprocess_image(images[i], target_size)\n",
        "                        image2 = utility.download_and_preprocess_image(images[j], target_size)\n",
        "\n",
        "                        # Convert tensors to lists of pixel values\n",
        "                        image1_list = tensor_to_list(image1)\n",
        "                        image2_list = tensor_to_list(image2)\n",
        "\n",
        "                        pet_data_pairs.append({\n",
        "                            \"plemeno1\": plemeno,\n",
        "                            \"vek1\": vek,\n",
        "                            \"barva1\": barva,\n",
        "                            \"velikost1\": velikost,\n",
        "                            \"fotka1\": image1_list,\n",
        "                            \"plemeno2\": plemeno,\n",
        "                            \"vek2\": vek,\n",
        "                            \"barva2\": barva,\n",
        "                            \"velikost2\": velikost,\n",
        "                            \"fotka2\": image2_list,\n",
        "                            \"label\": 1\n",
        "                        })\n",
        "                        same_pet_pair_count += 1\n",
        "\n",
        "                        # Mark this pair as processed\n",
        "                        processed_same_pairs.add(pair_id)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing same-pet pair ({images[i]}, {images[j]}): {e}\")\n",
        "\n",
        "            # Check if we broke out of the loop due to too many duplicates\n",
        "            if duplicate_skip_count > 3:\n",
        "                break\n",
        "\n",
        "        # Now, create different-pet pairs until max_diff_pet_pairs is reached\n",
        "        print(f\"Processing different-pet pairs for {key}...\")\n",
        "        valid_diff_pair_attempts = 0  # To track valid attempts for different-pet pairs\n",
        "\n",
        "        while diff_pet_pair_count < max_diff_pet_pairs:\n",
        "            other_pets = [k for k in all_keys if k != key]  # List of all other pets\n",
        "            if not other_pets:\n",
        "                break\n",
        "\n",
        "            key2 = random.choice(other_pets)  # Randomly select another pet\n",
        "            entry2 = metadata[key2]\n",
        "            plemeno2 = entry2.get(\"Plemeno\", \"Unknown\")\n",
        "            vek2 = entry2.get(\"Věk\", \"Unknown\")\n",
        "            barva2 = entry2.get(\"Barva\", \"Unknown\")\n",
        "            velikost2 = entry2.get(\"Velikost\", \"Unknown\")\n",
        "            images2 = entry2.get(\"images\", [])\n",
        "\n",
        "            if not images2:\n",
        "                print(f\"Skipping different-pet pair ({key}, {key2}): Missing images for {key2}.\")\n",
        "                continue\n",
        "\n",
        "            # Create a unique identifier for the different-pet pair\n",
        "            diff_pair_id = tuple(sorted([key, key2]))  # Sorting ensures no duplicates between pets\n",
        "\n",
        "            if diff_pair_id in processed_diff_pairs:\n",
        "                print(f\"Skipping duplicate different-pet pair: {key} and {key2}\")\n",
        "                valid_diff_pair_attempts += 1\n",
        "                if valid_diff_pair_attempts > 10:  # Allow up to 10 attempts\n",
        "                    print(f\"No more valid different-pet pairs for {key}. Moving to next part.\")\n",
        "                    break  # Skip this pet and move to the next part if no valid pairs found\n",
        "                continue  # Skip if the pair has already been processed\n",
        "\n",
        "            try:\n",
        "                print(f\"Processing different-pet pair: {key} ({images[0]}) and {key2} ({images2[0]})\")\n",
        "                image1 = utility.download_and_preprocess_image(images[0], target_size)\n",
        "                image2 = utility.download_and_preprocess_image(images2[0], target_size)\n",
        "\n",
        "                # Convert tensors to lists of pixel values\n",
        "                image1_list = tensor_to_list(image1)\n",
        "                image2_list = tensor_to_list(image2)\n",
        "\n",
        "                pet_data_pairs.append({\n",
        "                    \"plemeno1\": plemeno,\n",
        "                    \"vek1\": vek,\n",
        "                    \"barva1\": barva,\n",
        "                    \"velikost1\": velikost,\n",
        "                    \"fotka1\": image1_list,\n",
        "                    \"plemeno2\": plemeno2,\n",
        "                    \"vek2\": vek2,\n",
        "                    \"barva2\": barva2,\n",
        "                    \"velikost2\": velikost2,\n",
        "                    \"fotka2\": image2_list,\n",
        "                    \"label\": 0\n",
        "                })\n",
        "\n",
        "                diff_pet_pair_count += 1\n",
        "                pet_pair_count[key] += 1\n",
        "                pet_pair_count[key2] += 1\n",
        "\n",
        "                # Mark this pair as processed\n",
        "                processed_diff_pairs.add(diff_pair_id)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing different-pet pair ({key}, {key2}): {e}\")\n",
        "\n",
        "        print(f\"Finished processing for {key}. Total same-pet pairs: {same_pet_pair_count}, Total different-pet pairs: {diff_pet_pair_count}\")\n",
        "\n",
        "        # After processing this pet, save the pairs for this specific pet to a JSON file\n",
        "        save_pet_pairs_to_json(pet_data_pairs, key)\n",
        "\n",
        "    print(\"Dataset preprocessing completed.\")\n",
        "    return data_pairs\n"
      ],
      "metadata": {
        "id": "NrIlZM3N-9GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Triggering the result function"
      ],
      "metadata": {
        "id": "GSwHfCmUXueQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Fetching metadata...\")\n",
        "    metadata = utility.get_data()\n",
        "    verify_metadata(metadata)\n",
        "\n",
        "    print(\"Filtering metadata to remove entries without images...\")\n",
        "    filtered_metadata = filter_metadata_with_images(metadata)\n",
        "    print(f\"Filtered metadata contains {len(filtered_metadata)} entries (original: {len(metadata)})\")\n",
        "\n",
        "    # Limit to the specified entries for testing\n",
        "    filtered_metadata = dict(islice(filtered_metadata.items(), 5))\n",
        "    print(f\"Using the first {len(filtered_metadata)} entries for testing.\")\n",
        "\n",
        "    verify_metadata(filtered_metadata)\n",
        "\n",
        "    print(\"Creating dataset...\")\n",
        "    max_same_pet_pairs = 2  # Max same-pet pairs per pet\n",
        "    max_diff_pet_pairs = 2  # Max different-pet pairs per pet\n",
        "    target_size = (96, 96)\n",
        "    dataset = preprocess_dataset_random(filtered_metadata, target_size, max_same_pet_pairs, max_diff_pet_pairs)\n"
      ],
      "metadata": {
        "id": "KwL9xoSM19eb",
        "outputId": "f0ebfb6b-33c9-4c7a-932e-4ece6b8ca2e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching metadata...\n",
            "Filtering metadata to remove entries without images...\n",
            "Filtered metadata contains 10328 entries (original: 12050)\n",
            "Using the first 5 entries for testing.\n",
            "Creating dataset...\n",
            "Starting dataset preprocessing...\n",
            "Starting from pet tanyny-chomutov-2024-12-21 at index 0...\n",
            "Processing pet tanyny-chomutov-2024-12-21 (1/5)...\n",
            "Processing same-pet pairs for tanyny-chomutov-2024-12-21...\n",
            "Processing same-pet pair: https://www.psidetektiv.cz/data/catalog/big/2024/12/22/img190394.jpg and https://www.psidetektiv.cz/data/catalog/big/2024/12/22/img190392.jpg for tanyny-chomutov-2024-12-21\n",
            "Uploading model...\n",
            "Model loaded successfully.\n",
            "Processing same-pet pair: https://www.psidetektiv.cz/data/catalog/big/2024/12/22/img190394.jpg and https://www.psidetektiv.cz/data/catalog/big/2024/12/22/img190393.jpg for tanyny-chomutov-2024-12-21\n",
            "Processing different-pet pairs for tanyny-chomutov-2024-12-21...\n",
            "Processing different-pet pair: tanyny-chomutov-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/22/img190394.jpg) and egy-karlovy-vary-2024-12-17 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190378.jpg)\n",
            "Skipping duplicate different-pet pair: tanyny-chomutov-2024-12-21 and egy-karlovy-vary-2024-12-17\n",
            "Processing different-pet pair: tanyny-chomutov-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/22/img190394.jpg) and cira-a-kaja-jihlava-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190362.jpg)\n",
            "Finished processing for tanyny-chomutov-2024-12-21. Total same-pet pairs: 2, Total different-pet pairs: 2\n",
            "Pairs for tanyny-chomutov-2024-12-21 successfully saved to pet_pairs.json\n",
            "Processing pet haily-tachov-2024-12-21 (2/5)...\n",
            "Processing same-pet pairs for haily-tachov-2024-12-21...\n",
            "Processing same-pet pair: https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190383.jpg and https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190384.jpg for haily-tachov-2024-12-21\n",
            "Processing different-pet pairs for haily-tachov-2024-12-21...\n",
            "Processing different-pet pair: haily-tachov-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190383.jpg) and randy-vyskov-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190367.jpg)\n",
            "Skipping duplicate different-pet pair: haily-tachov-2024-12-21 and randy-vyskov-2024-12-21\n",
            "Skipping duplicate different-pet pair: haily-tachov-2024-12-21 and randy-vyskov-2024-12-21\n",
            "Skipping duplicate different-pet pair: haily-tachov-2024-12-21 and randy-vyskov-2024-12-21\n",
            "Skipping duplicate different-pet pair: haily-tachov-2024-12-21 and randy-vyskov-2024-12-21\n",
            "Processing different-pet pair: haily-tachov-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190383.jpg) and egy-karlovy-vary-2024-12-17 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190378.jpg)\n",
            "Finished processing for haily-tachov-2024-12-21. Total same-pet pairs: 1, Total different-pet pairs: 2\n",
            "Pairs for haily-tachov-2024-12-21 successfully saved to pet_pairs.json\n",
            "Processing pet egy-karlovy-vary-2024-12-17 (3/5)...\n",
            "Processing same-pet pairs for egy-karlovy-vary-2024-12-17...\n",
            "Processing same-pet pair: https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190381.jpg and https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190379.jpg for egy-karlovy-vary-2024-12-17\n",
            "Processing different-pet pairs for egy-karlovy-vary-2024-12-17...\n",
            "Processing different-pet pair: egy-karlovy-vary-2024-12-17 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190381.jpg) and haily-tachov-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190383.jpg)\n",
            "Skipping duplicate different-pet pair: egy-karlovy-vary-2024-12-17 and haily-tachov-2024-12-21\n",
            "Skipping duplicate different-pet pair: egy-karlovy-vary-2024-12-17 and haily-tachov-2024-12-21\n",
            "Processing different-pet pair: egy-karlovy-vary-2024-12-17 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190381.jpg) and randy-vyskov-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190367.jpg)\n",
            "Finished processing for egy-karlovy-vary-2024-12-17. Total same-pet pairs: 1, Total different-pet pairs: 2\n",
            "Pairs for egy-karlovy-vary-2024-12-17 successfully saved to pet_pairs.json\n",
            "Processing pet randy-vyskov-2024-12-21 (4/5)...\n",
            "Processing same-pet pairs for randy-vyskov-2024-12-21...\n",
            "Processing same-pet pair: https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190368.jpg and https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190367.jpg for randy-vyskov-2024-12-21\n",
            "Processing different-pet pairs for randy-vyskov-2024-12-21...\n",
            "Processing different-pet pair: randy-vyskov-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190368.jpg) and tanyny-chomutov-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/22/img190394.jpg)\n",
            "Processing different-pet pair: randy-vyskov-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190368.jpg) and cira-a-kaja-jihlava-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190362.jpg)\n",
            "Finished processing for randy-vyskov-2024-12-21. Total same-pet pairs: 1, Total different-pet pairs: 2\n",
            "Pairs for randy-vyskov-2024-12-21 successfully saved to pet_pairs.json\n",
            "Processing pet cira-a-kaja-jihlava-2024-12-21 (5/5)...\n",
            "Processing same-pet pairs for cira-a-kaja-jihlava-2024-12-21...\n",
            "Processing same-pet pair: https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190363.jpg and https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190362.jpg for cira-a-kaja-jihlava-2024-12-21\n",
            "Processing different-pet pairs for cira-a-kaja-jihlava-2024-12-21...\n",
            "Processing different-pet pair: cira-a-kaja-jihlava-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190363.jpg) and haily-tachov-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190383.jpg)\n",
            "Processing different-pet pair: cira-a-kaja-jihlava-2024-12-21 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190363.jpg) and egy-karlovy-vary-2024-12-17 (https://www.psidetektiv.cz/data/catalog/big/2024/12/21/img190381.jpg)\n",
            "Finished processing for cira-a-kaja-jihlava-2024-12-21. Total same-pet pairs: 1, Total different-pet pairs: 2\n",
            "Pairs for cira-a-kaja-jihlava-2024-12-21 successfully saved to pet_pairs.json\n",
            "Dataset preprocessing completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Yh_5TrjkZ5lP"
      }
    }
  ]
}