{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0rE2nfNFO48RJb41Er5wr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avkaz/DeepLearningPetIdentification/blob/preprocess_pipeline/preprop_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "J5yEKEaHmNW3"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from PIL import Image, ExifTags, ImageDraw\n",
        "import requests\n",
        "import io\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Metadata Fetching\n",
        "def get_data():\n",
        "    \"\"\"\n",
        "    Fetches and parses JSON data from the given URL.\n",
        "\n",
        "    Returns:\n",
        "        dict: The parsed JSON data as a Python dictionary.\n",
        "    \"\"\"\n",
        "    url = \"https://raw.githubusercontent.com/avkaz/DeepLearningPetIdentification/main/pets_db.json\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"An error occurred while fetching data: {e}\")\n",
        "        raise\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"An error occurred while parsing JSON: {e}\")\n",
        "        raise\n",
        "\n",
        "# Model Loading\n",
        "detector = None\n",
        "MODEL_URL = \"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total number of \"pets\", where metadata: \"images\" is empty."
      ],
      "metadata": {
        "id": "3D66ZMUl1GD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count and print entries with empty 'images' list\n",
        "empty_images_count = sum(1 for entry in metadata.values() if not entry.get(\"images\"))\n",
        "\n",
        "# Print the result\n",
        "print(f\"Number of entries with empty images: {empty_images_count}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EvlutCNzFOr",
        "outputId": "980fb3f2-5a66-449a-ef7f-1e1400f22223"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries with empty images: 1722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_detector_model():\n",
        "    global detector\n",
        "    if detector is None:\n",
        "        print(\"Uploading model...\")\n",
        "        detector = hub.load(MODEL_URL).signatures['serving_default']\n",
        "        print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "id": "3dKhT-_8nUIK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metadata Verification\n",
        "def verify_metadata(metadata):\n",
        "    \"\"\"\n",
        "    Verifies metadata integrity by checking for missing or inconsistent entries.\n",
        "\n",
        "    Args:\n",
        "        metadata (dict): The metadata dictionary to verify.\n",
        "    \"\"\"\n",
        "    for key, value in metadata.items():\n",
        "        if not isinstance(value, dict) or \"label\" not in value or \"images\" not in value:\n",
        "            print(f\"Warning: Incomplete metadata for key {key}: {value}\")\n",
        "\n",
        "# Orientation Correction\n",
        "def fix_orientation(image):\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = image._getexif()\n",
        "        if exif is not None:\n",
        "            orientation = exif.get(orientation)\n",
        "            if orientation == 3:\n",
        "                image = image.rotate(180, expand=True)\n",
        "            elif orientation == 6:\n",
        "                image = image.rotate(270, expand=True)\n",
        "            elif orientation == 8:\n",
        "                image = image.rotate(90, expand=True)\n",
        "    except (AttributeError, KeyError, IndexError):\n",
        "        pass\n",
        "    return image\n",
        "\n",
        "# Cropping and Resizing\n",
        "def crop_and_resize(image, bounding_box, target_size):\n",
        "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "    x1, y1, x2, y2 = bounding_box\n",
        "    image = tf.strided_slice(image, [int(y1), int(x1), 0], [int(y2), int(x2), 3])\n",
        "    image = tf.image.resize(image, target_size)\n",
        "    return image\n",
        "\n",
        "# Pet Detection\n",
        "def detect_pet(image):\n",
        "    load_detector_model()\n",
        "    input_tensor = tf.image.resize(image, [640, 640]) / 255.0\n",
        "    input_tensor = tf.expand_dims(input_tensor, axis=0)\n",
        "    input_tensor_uint8 = tf.cast(input_tensor * 255.0, tf.uint8)\n",
        "\n",
        "    result = detector(tf.convert_to_tensor(input_tensor_uint8))\n",
        "    result = {key: value.numpy() for key, value in result.items()}\n",
        "\n",
        "    if 'detection_classes' in result and 'detection_scores' in result:\n",
        "        detected_classes = result['detection_classes']\n",
        "        detected_boxes = result['detection_boxes']\n",
        "        detected_scores = result['detection_scores']\n",
        "        pet_classes = [b\"Cat\", b\"Dog\", b\"Animal\"]\n",
        "\n",
        "        for idx in range(len(detected_classes[0])):\n",
        "            detected_class = detected_classes[0][idx]\n",
        "            detected_score = detected_scores[0][idx]\n",
        "            detected_box = detected_boxes[0][idx]\n",
        "\n",
        "            if detected_class in pet_classes and detected_score > 0.5:\n",
        "                return detected_box\n",
        "    return None\n",
        "\n",
        "# Detection Visualization\n",
        "def visualize_detection(image, bounding_box, title=\"Detection Visualization\"):\n",
        "    \"\"\"\n",
        "    Displays an image with a bounding box for detected pets.\n",
        "\n",
        "    Args:\n",
        "        image: The input image (PIL Image).\n",
        "        bounding_box: Bounding box coordinates (x1, y1, x2, y2).\n",
        "        title: Title for the visualization.\n",
        "    \"\"\"\n",
        "    if bounding_box:\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        x1, y1, x2, y2 = [int(coord) for coord in bounding_box]\n",
        "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=3)\n",
        "    plt.imshow(image)\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Download and Preprocess Image\n",
        "def download_and_preprocess_image(url, target_size=(224, 224), visualize=False):\n",
        "    response = requests.get(url)\n",
        "    image_bytes = response.content\n",
        "    pil_image = Image.open(io.BytesIO(image_bytes))\n",
        "    pil_image = fix_orientation(pil_image)\n",
        "\n",
        "    image = tf.convert_to_tensor(np.array(pil_image), dtype=tf.float32) / 255.0\n",
        "    bounding_box = detect_pet(image)\n",
        "\n",
        "    if bounding_box is not None:\n",
        "        image = crop_and_resize(image, bounding_box, target_size)\n",
        "        if visualize:\n",
        "            visualize_detection(pil_image, bounding_box)\n",
        "    else:\n",
        "        image = tf.image.resize_with_crop_or_pad(image, target_size[0], target_size[1])\n",
        "    return image"
      ],
      "metadata": {
        "id": "PKEM6JzRnODf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function processes image data from a metadata dictionary and prepares it for training in a machine learning model using TensorFlow."
      ],
      "metadata": {
        "id": "XJ1TWxIa2dh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Creation\n",
        "#def preprocess_pipeline(metadata, target_size=(224, 224), visualize=False):\n",
        " #   images = []\n",
        "  #  labels = []\n",
        "   # for key, entry in metadata.items():\n",
        "    #    image_url = entry[\"images\"]\n",
        "     #   label = entry[\"Plemeno\"]\n",
        "      #  image = download_and_preprocess_image(image_url, target_size, visualize)\n",
        "       # images.append(image)\n",
        "        #labels.append(label)\n",
        "   # return tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "\n",
        "def preprocess_pipeline(metadata, target_size=(224, 224), visualize=False):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for key, entry in metadata.items():\n",
        "        image_urls = entry[\"images\"]\n",
        "\n",
        "        # Create a label (list of characteristics)\n",
        "        label = [\n",
        "            entry.get(\"Plemeno\", \"Unknown\"),\n",
        "            entry.get(\"VÄ›k\", \"Unknown\"),\n",
        "            entry.get(\"Barva\", \"Unknown\"),\n",
        "            entry.get(\"Velikost\", \"Unknown\")\n",
        "        ]\n",
        "\n",
        "        # Process all the images in the 'images' list\n",
        "        for image_url in image_urls:\n",
        "            image = download_and_preprocess_image(image_url, target_size, visualize)\n",
        "            images.append(image)\n",
        "            labels.append(label)  # Append the same label for each image\n",
        "\n",
        "    return tf.data.Dataset.from_tensor_slices((images, labels))"
      ],
      "metadata": {
        "id": "Zsz7r57y1xUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function will display a specified number of sample images from the dataset, with the corresponding labels shown as the image title."
      ],
      "metadata": {
        "id": "AW3mtPkN2uE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Sample Visualization\n",
        "def visualize_dataset_sample(dataset, num_samples=5):\n",
        "    for image, label in dataset.take(num_samples):\n",
        "        plt.imshow(image.numpy())\n",
        "        plt.title(f\"Label: {label.numpy().decode()}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "IzbG8Y3_1387"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into parts: training, validation and test data.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QRZliIqo9aYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(dataset, val_split=0.1, test_split=0.1):\n",
        "    total_size = len(dataset)\n",
        "    val_size = int(val_split * total_size)\n",
        "    test_size = int(test_split * total_size)\n",
        "\n",
        "    val_dataset = dataset.take(val_size)\n",
        "    test_dataset = dataset.skip(val_size).take(test_size)\n",
        "    train_dataset = dataset.skip(val_size + test_size)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n"
      ],
      "metadata": {
        "id": "pnapjKEv9K7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function prepares the dataset by batching it into groups of a specified size. It can also shuffle the dataset before batching and prefetch it to optimize performance."
      ],
      "metadata": {
        "id": "Citsl0HQ3hMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Batching\n",
        "def batch_dataset(dataset, batch_size=32, shuffle=True):\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=1000)\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "hoevYCrQ2AIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Fetching metadata...\")\n",
        "    metadata = get_data()\n",
        "    verify_metadata(metadata)\n",
        "\n",
        "    print(\"Creating dataset...\")\n",
        "    dataset = preprocess_pipeline(metadata, visualize=True)\n",
        "\n",
        "    print(\"Visualizing dataset samples...\")\n",
        "    visualize_dataset_sample(dataset, num_samples=3)\n"
      ],
      "metadata": {
        "id": "KwL9xoSM19eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: label encoding, image augmentation?, performance optimization - parallel processing ..."
      ],
      "metadata": {
        "id": "gESHyuRcAp1x"
      }
    }
  ]
}