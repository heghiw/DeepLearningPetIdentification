{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avkaz/DeepLearningPetIdentification/blob/fixes/finetuned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQOjfsxTxrFF"
      },
      "source": [
        "## Downloading utility file and importing need dependesies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Ww1ukE-1TAoI"
      },
      "outputs": [],
      "source": [
        "\n",
        "import requests\n",
        "# Correct raw URL for the utility.py file\n",
        "url = \"https://raw.githubusercontent.com/avkaz/DeepLearningPetIdentification/main/utility.py\"\n",
        "\n",
        "# Fetch and save the file locally\n",
        "response = requests.get(url)\n",
        "with open(\"utility.py\", \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYrA3msXSuK9",
        "outputId": "efb44b69-4f27-4c83-867c-66579d4927e0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import io\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import random\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "import utility\n",
        "from itertools import islice\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3MzX9uex7cG"
      },
      "source": [
        "## Getting Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "google_drive_url = \"https://drive.google.com/file/d/1VR5GWGrVjEtJHEzTPIB-EHDQMG3UnmZ9/view?usp=sharing\"\n",
        "utility.download_file_from_google_drive(google_drive_url, \"./data/pets_pair.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YcAA8oE2JLn4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data successfully loaded and transformed.\n"
          ]
        }
      ],
      "source": [
        "data_in = utility.load_json_and_transform_lists_to_tensors('updated_data.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "53j6GaWPJiQn"
      },
      "outputs": [],
      "source": [
        "data = dict(list(data_in.items())[:200])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUVZ5qFxUCv9",
        "outputId": "b543e57d-ae65-430e-eb88-5c0da8521476"
      },
      "outputs": [],
      "source": [
        "model = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "bCpcsndYRt8W"
      },
      "outputs": [],
      "source": [
        "data= filter_pets_by_images(data_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkiMkjWvoky0",
        "outputId": "995e3b73-e47f-4570-eb64-2c5e1b1f3ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'tanyny-chomutov-2024-12-21': {'Jméno': 'Tanyny', 'Pohlaví': 'Samec', 'Kraj': 'Ústecký', 'Okres': 'Chomutov', 'Plemeno': 'Kříženec', 'Věk': '5 let', 'Barva': 'Černá', 'Velikost': 'Střední - 10-17kg', 'url': 'https://www.psidetektiv.cz/zvire/tanyny-chomutov-2024-12-21', 'images': <tf.Tensor: shape=(5, 224, 224, 3), dtype=float32, numpy=\n",
            "array([[[[0.53333336, 0.4117647 , 0.3019608 ],\n",
            "         [0.5294118 , 0.40784314, 0.29411766],\n",
            "         [0.54901963, 0.42745098, 0.3137255 ],\n",
            "         ...,\n",
            "         [0.28235295, 0.22352941, 0.14901961],\n",
            "         [0.2784314 , 0.21960784, 0.14509805],\n",
            "         [0.27450982, 0.21568628, 0.13333334]],\n",
            "\n",
            "        [[0.5411765 , 0.41960785, 0.30980393],\n",
            "         [0.56078434, 0.4392157 , 0.3254902 ],\n",
            "         [0.5568628 , 0.43529412, 0.3137255 ],\n",
            "         ...,\n",
            "         [0.30588236, 0.25490198, 0.18039216],\n",
            "         [0.29803923, 0.24705882, 0.17254902],\n",
            "         [0.29803923, 0.24705882, 0.17254902]],\n",
            "\n",
            "        [[0.5176471 , 0.40392157, 0.2784314 ],\n",
            "         [0.5411765 , 0.42745098, 0.29411766],\n",
            "         [0.5647059 , 0.45490196, 0.30980393],\n",
            "         ...,\n",
            "         [0.33333334, 0.27450982, 0.2       ],\n",
            "         [0.32941177, 0.27058825, 0.19607843],\n",
            "         [0.33333334, 0.27450982, 0.2       ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.10196079, 0.07450981, 0.05098039],\n",
            "         [0.10196079, 0.07450981, 0.05098039],\n",
            "         [0.10196079, 0.07450981, 0.05098039],\n",
            "         ...,\n",
            "         [0.61960787, 0.4862745 , 0.3372549 ],\n",
            "         [0.62352943, 0.49019608, 0.34117648],\n",
            "         [0.6313726 , 0.49803922, 0.34901962]],\n",
            "\n",
            "        [[0.10196079, 0.07450981, 0.05098039],\n",
            "         [0.10196079, 0.07450981, 0.05098039],\n",
            "         [0.10196079, 0.07450981, 0.05098039],\n",
            "         ...,\n",
            "         [0.62352943, 0.49411765, 0.33333334],\n",
            "         [0.6313726 , 0.5019608 , 0.34117648],\n",
            "         [0.64705884, 0.5176471 , 0.35686275]],\n",
            "\n",
            "        [[0.10196079, 0.07450981, 0.05098039],\n",
            "         [0.10196079, 0.07450981, 0.05098039],\n",
            "         [0.10196079, 0.07450981, 0.05098039],\n",
            "         ...,\n",
            "         [0.62352943, 0.49411765, 0.33333334],\n",
            "         [0.6392157 , 0.5019608 , 0.34509805],\n",
            "         [0.6666667 , 0.5294118 , 0.37254903]]],\n",
            "\n",
            "\n",
            "       [[[0.09803922, 0.11372549, 0.14901961],\n",
            "         [0.13725491, 0.16470589, 0.19607843],\n",
            "         [0.15686275, 0.18431373, 0.22352941],\n",
            "         ...,\n",
            "         [0.52156866, 0.42745098, 0.38039216],\n",
            "         [0.5294118 , 0.42745098, 0.3764706 ],\n",
            "         [0.5137255 , 0.4117647 , 0.36078432]],\n",
            "\n",
            "        [[0.14509805, 0.16078432, 0.19607843],\n",
            "         [0.15686275, 0.17254902, 0.20784314],\n",
            "         [0.1764706 , 0.19215687, 0.23529412],\n",
            "         ...,\n",
            "         [0.53333336, 0.4392157 , 0.39215687],\n",
            "         [0.53333336, 0.43137255, 0.38039216],\n",
            "         [0.5137255 , 0.4117647 , 0.36078432]],\n",
            "\n",
            "        [[0.10980392, 0.1254902 , 0.16078432],\n",
            "         [0.15686275, 0.17254902, 0.20784314],\n",
            "         [0.18039216, 0.19607843, 0.23921569],\n",
            "         ...,\n",
            "         [0.5372549 , 0.44313726, 0.39607844],\n",
            "         [0.5372549 , 0.43529412, 0.38431373],\n",
            "         [0.52156866, 0.41960785, 0.36862746]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.38431373, 0.28627452, 0.25882354],\n",
            "         [0.4       , 0.3019608 , 0.27450982],\n",
            "         [0.39215687, 0.3019608 , 0.27058825],\n",
            "         ...,\n",
            "         [0.45882353, 0.36078432, 0.33333334],\n",
            "         [0.43529412, 0.3372549 , 0.30980393],\n",
            "         [0.42352942, 0.3254902 , 0.29803923]],\n",
            "\n",
            "        [[0.39607844, 0.29803923, 0.27058825],\n",
            "         [0.39607844, 0.29803923, 0.27058825],\n",
            "         [0.3882353 , 0.29803923, 0.26666668],\n",
            "         ...,\n",
            "         [0.45882353, 0.36078432, 0.33333334],\n",
            "         [0.43529412, 0.3372549 , 0.30980393],\n",
            "         [0.42352942, 0.3254902 , 0.29803923]],\n",
            "\n",
            "        [[0.4       , 0.3019608 , 0.27450982],\n",
            "         [0.38431373, 0.28627452, 0.25882354],\n",
            "         [0.38431373, 0.29411766, 0.2627451 ],\n",
            "         ...,\n",
            "         [0.45882353, 0.36078432, 0.33333334],\n",
            "         [0.43137255, 0.33333334, 0.30588236],\n",
            "         [0.42352942, 0.3254902 , 0.29803923]]],\n",
            "\n",
            "\n",
            "       [[[0.85490197, 0.69803923, 0.7019608 ],\n",
            "         [0.8509804 , 0.69411767, 0.69803923],\n",
            "         [0.84705883, 0.6901961 , 0.69411767],\n",
            "         ...,\n",
            "         [0.85490197, 0.6901961 , 0.7058824 ],\n",
            "         [0.85882354, 0.69411767, 0.70980394],\n",
            "         [0.85882354, 0.69411767, 0.70980394]],\n",
            "\n",
            "        [[0.8392157 , 0.68235296, 0.6862745 ],\n",
            "         [0.84313726, 0.6862745 , 0.6901961 ],\n",
            "         [0.8509804 , 0.69411767, 0.69803923],\n",
            "         ...,\n",
            "         [0.85490197, 0.6901961 , 0.7058824 ],\n",
            "         [0.85490197, 0.6901961 , 0.7058824 ],\n",
            "         [0.85490197, 0.6901961 , 0.7058824 ]],\n",
            "\n",
            "        [[0.84313726, 0.6862745 , 0.6901961 ],\n",
            "         [0.84705883, 0.6901961 , 0.69411767],\n",
            "         [0.8509804 , 0.69411767, 0.69803923],\n",
            "         ...,\n",
            "         [0.8509804 , 0.6862745 , 0.7019608 ],\n",
            "         [0.85490197, 0.6901961 , 0.7058824 ],\n",
            "         [0.85490197, 0.6901961 , 0.7058824 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.68235296, 0.1254902 , 0.28235295],\n",
            "         [0.6862745 , 0.12941177, 0.28627452],\n",
            "         [0.6862745 , 0.12941177, 0.28627452],\n",
            "         ...,\n",
            "         [0.70980394, 0.14901961, 0.31764707],\n",
            "         [0.7058824 , 0.14509805, 0.3137255 ],\n",
            "         [0.7058824 , 0.14509805, 0.3137255 ]],\n",
            "\n",
            "        [[0.6862745 , 0.12941177, 0.28627452],\n",
            "         [0.6862745 , 0.12941177, 0.28627452],\n",
            "         [0.6901961 , 0.13333334, 0.2901961 ],\n",
            "         ...,\n",
            "         [0.7058824 , 0.14509805, 0.3137255 ],\n",
            "         [0.7058824 , 0.14509805, 0.3137255 ],\n",
            "         [0.7058824 , 0.14509805, 0.3137255 ]],\n",
            "\n",
            "        [[0.6862745 , 0.12941177, 0.28627452],\n",
            "         [0.6862745 , 0.12941177, 0.28627452],\n",
            "         [0.6901961 , 0.13333334, 0.2901961 ],\n",
            "         ...,\n",
            "         [0.70980394, 0.14901961, 0.31764707],\n",
            "         [0.70980394, 0.14901961, 0.31764707],\n",
            "         [0.70980394, 0.14901961, 0.31764707]]],\n",
            "\n",
            "\n",
            "       [[[0.74509805, 0.6784314 , 0.6392157 ],\n",
            "         [0.69803923, 0.6313726 , 0.5921569 ],\n",
            "         [0.7058824 , 0.6392157 , 0.6       ],\n",
            "         ...,\n",
            "         [0.78039217, 0.7764706 , 0.76862746],\n",
            "         [0.76862746, 0.7647059 , 0.75686276],\n",
            "         [0.78039217, 0.7764706 , 0.76862746]],\n",
            "\n",
            "        [[0.77254903, 0.7058824 , 0.6666667 ],\n",
            "         [0.74509805, 0.6784314 , 0.6392157 ],\n",
            "         [0.7411765 , 0.6745098 , 0.63529414],\n",
            "         ...,\n",
            "         [0.80784315, 0.80784315, 0.8       ],\n",
            "         [0.79607844, 0.79607844, 0.7882353 ],\n",
            "         [0.7882353 , 0.7882353 , 0.78039217]],\n",
            "\n",
            "        [[0.7921569 , 0.7372549 , 0.69411767],\n",
            "         [0.7882353 , 0.73333335, 0.6901961 ],\n",
            "         [0.77254903, 0.7176471 , 0.68235296],\n",
            "         ...,\n",
            "         [0.827451  , 0.8235294 , 0.8156863 ],\n",
            "         [0.8156863 , 0.8117647 , 0.8039216 ],\n",
            "         [0.8       , 0.79607844, 0.7882353 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.70980394, 0.6745098 , 0.64705884],\n",
            "         [0.7019608 , 0.6666667 , 0.6392157 ],\n",
            "         [0.74509805, 0.70980394, 0.68235296],\n",
            "         ...,\n",
            "         [0.70980394, 0.69803923, 0.67058825],\n",
            "         [0.7019608 , 0.68235296, 0.65882355],\n",
            "         [0.6901961 , 0.67058825, 0.64705884]],\n",
            "\n",
            "        [[0.7019608 , 0.6627451 , 0.627451  ],\n",
            "         [0.7019608 , 0.6666667 , 0.6313726 ],\n",
            "         [0.6862745 , 0.6509804 , 0.6156863 ],\n",
            "         ...,\n",
            "         [0.7058824 , 0.69411767, 0.6666667 ],\n",
            "         [0.7019608 , 0.68235296, 0.65882355],\n",
            "         [0.7058824 , 0.6862745 , 0.6627451 ]],\n",
            "\n",
            "        [[0.69411767, 0.654902  , 0.61960787],\n",
            "         [0.69411767, 0.654902  , 0.61960787],\n",
            "         [0.68235296, 0.6431373 , 0.60784316],\n",
            "         ...,\n",
            "         [0.7294118 , 0.7019608 , 0.67058825],\n",
            "         [0.72156864, 0.69411767, 0.67058825],\n",
            "         [0.7254902 , 0.69803923, 0.6666667 ]]],\n",
            "\n",
            "\n",
            "       [[[0.7764706 , 0.7372549 , 0.6901961 ],\n",
            "         [0.7882353 , 0.7490196 , 0.7019608 ],\n",
            "         [0.7882353 , 0.7411765 , 0.69411767],\n",
            "         ...,\n",
            "         [0.7764706 , 0.81960785, 0.827451  ],\n",
            "         [0.78039217, 0.8235294 , 0.83137256],\n",
            "         [0.78039217, 0.8235294 , 0.83137256]],\n",
            "\n",
            "        [[0.7764706 , 0.7372549 , 0.6901961 ],\n",
            "         [0.7882353 , 0.7490196 , 0.7019608 ],\n",
            "         [0.7882353 , 0.7411765 , 0.69411767],\n",
            "         ...,\n",
            "         [0.7764706 , 0.81960785, 0.827451  ],\n",
            "         [0.78039217, 0.8235294 , 0.83137256],\n",
            "         [0.78039217, 0.8235294 , 0.83137256]],\n",
            "\n",
            "        [[0.7764706 , 0.7372549 , 0.6901961 ],\n",
            "         [0.7882353 , 0.7490196 , 0.7019608 ],\n",
            "         [0.7921569 , 0.74509805, 0.69803923],\n",
            "         ...,\n",
            "         [0.7764706 , 0.81960785, 0.827451  ],\n",
            "         [0.7764706 , 0.81960785, 0.827451  ],\n",
            "         [0.78039217, 0.8235294 , 0.83137256]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.7372549 , 0.70980394, 0.6862745 ],\n",
            "         [0.73333335, 0.7058824 , 0.68235296],\n",
            "         [0.73333335, 0.69803923, 0.6784314 ],\n",
            "         ...,\n",
            "         [0.6117647 , 0.6392157 , 0.67058825],\n",
            "         [0.6117647 , 0.6392157 , 0.67058825],\n",
            "         [0.6117647 , 0.6392157 , 0.67058825]],\n",
            "\n",
            "        [[0.7411765 , 0.7137255 , 0.6901961 ],\n",
            "         [0.73333335, 0.7058824 , 0.68235296],\n",
            "         [0.7294118 , 0.69411767, 0.6745098 ],\n",
            "         ...,\n",
            "         [0.60784316, 0.63529414, 0.6666667 ],\n",
            "         [0.60784316, 0.63529414, 0.6666667 ],\n",
            "         [0.6117647 , 0.6392157 , 0.67058825]],\n",
            "\n",
            "        [[0.7411765 , 0.7137255 , 0.6901961 ],\n",
            "         [0.73333335, 0.7058824 , 0.68235296],\n",
            "         [0.7294118 , 0.69411767, 0.6745098 ],\n",
            "         ...,\n",
            "         [0.60784316, 0.63529414, 0.6666667 ],\n",
            "         [0.60784316, 0.63529414, 0.6666667 ],\n",
            "         [0.60784316, 0.63529414, 0.6666667 ]]]], dtype=float32)>}}\n"
          ]
        }
      ],
      "source": [
        "print(dict(list(data_in.items())[:1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdUIrhQeSLNy"
      },
      "source": [
        "## Generatin embeding using base model to simplify and speed up learning for future model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4Ruud12UbGsm",
        "outputId": "be56f2a6-eaab-4746-9f9e-882ced940546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 408 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x32f68e280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n"
          ]
        }
      ],
      "source": [
        "# create a mapping of pet identifiers to integer indices\n",
        "pet_ids = list(data.keys())\n",
        "pet_to_idx = {pet_id: idx for idx, pet_id in enumerate(pet_ids)}\n",
        "\n",
        "# generate embeddings for all pets and store them\n",
        "embeddings_dict = {\n",
        "    pet_key: generate_embeddings(model, pet_info['images'])\n",
        "    for pet_key, pet_info in data.items()\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating triplets for fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Wvn63JCWOj2v"
      },
      "outputs": [],
      "source": [
        "def generate_triplet(pet_key, pet_info, embeddings_dict, data):\n",
        "    embeddings = embeddings_dict[pet_key]  # use pre-generated embeddings\n",
        "\n",
        "    # create triplets: anchor, positive, and negative\n",
        "    for i in range(len(embeddings)):\n",
        "        anchor = embeddings[i]\n",
        "\n",
        "        # pick a random positive example from the same pet's observation, excluding the anchor image\n",
        "        positive_idx = np.random.choice([idx for idx in range(len(embeddings)) if idx != i ])\n",
        "        positive = embeddings[positive_idx]\n",
        "\n",
        "        # pick a random negative example (different pet)\n",
        "        negative_pet_key = np.random.choice([key for key in data if key != pet_key])\n",
        "        negative_embedding = embeddings_dict[negative_pet_key][0]\n",
        "        #print(i)\n",
        "        #print(positive_idx)\n",
        "        #print(negative_pet_key)\n",
        "        yield [anchor, positive, negative_embedding], pet_to_idx[pet_key]\n",
        "    #print(embeddings_dict[pet_key])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "RuQi2eebRlFL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# triplet training\n",
        "triplets = []\n",
        "labels = []\n",
        "\n",
        "for pet_key, pet_info in data.items():\n",
        "    for triplet, label in generate_triplet(pet_key, pet_info, embeddings_dict, data):\n",
        "        triplets.append(triplet)\n",
        "        labels.append(label)\n",
        "\n",
        "# Convert triplets to numpy array\n",
        "triplets = np.array(triplets)\n",
        "\n",
        "# Flatten the embeddings for FAISS\n",
        "flattened_triplets = np.array([\n",
        "    np.concatenate([anchor.flatten(), positive.flatten(), negative.flatten()])\n",
        "    for anchor, positive, negative in triplets\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Fine tuning the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "W_3Fgr-AjG-C",
        "outputId": "97c76fcc-733c-4fda-9882-451813b2d48a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000  \n",
            "Epoch 2/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0000\n",
            "Epoch 3/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0000\n",
            "Epoch 4/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 5/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 \n",
            "Epoch 6/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 7/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 8/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 9/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0000\n",
            "Epoch 10/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 11/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 12/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 13/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 14/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0000\n",
            "Epoch 15/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 16/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 \n",
            "Epoch 17/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 18/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 19/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 \n",
            "Epoch 20/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 21/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 22/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 23/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0000\n",
            "Epoch 24/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 25/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0000\n",
            "Epoch 26/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 27/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 28/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 29/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0000 \n",
            "Epoch 30/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0000\n",
            "Epoch 31/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 32/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 33/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 \n",
            "Epoch 34/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 35/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 \n",
            "Epoch 36/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0000\n",
            "Epoch 37/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0000\n",
            "Epoch 38/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 \n",
            "Epoch 39/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 \n",
            "Epoch 40/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 41/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 \n",
            "Epoch 42/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 43/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 44/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 45/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 46/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 47/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 48/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 49/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 50/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0000 \n",
            "Epoch 51/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 52/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 53/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 54/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 \n",
            "Epoch 55/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 56/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 \n",
            "Epoch 57/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0000 \n",
            "Epoch 58/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0000\n",
            "Epoch 59/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n",
            "Epoch 60/60\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0000 \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x333b04430>"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(flattened_triplets, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize FAISS index for similarity search\n",
        "embedding_dim = X_train.shape[1]  # The size of the flattened embeddings\n",
        "index = faiss.IndexFlatL2(embedding_dim)  # L2 distance metric for similarity search\n",
        "\n",
        "# Add training data embeddings to the FAISS index\n",
        "index.add(X_train)  # No need to reshape, as X_train is already flat\n",
        "\n",
        "\n",
        "input_dim = 3840\n",
        "\n",
        "# Create the model\n",
        "model = create_model(input_dim)\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss=lambda y_true, y_pred: triplet_loss(y_true, y_pred, margin=1.0))\n",
        "model.fit(X_train, np.array(y_train), epochs=60, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Precision: 0.0006\n",
            "Recall: 0.0247\n",
            "F1-score: 0.0012\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kazakovalexey/Documents/Studium/VSE/Mgr/AI/petsDetection/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert continuous predictions to discrete labels (if it's multiclass classification)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)  # For multiclass, you need to take the class with the highest probability\n",
        "\n",
        "# Calculate precision, recall, and F1-score with multiclass average\n",
        "precision = precision_score(y_test, y_pred_labels, average='weighted') \n",
        "recall = recall_score(y_test, y_pred_labels, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_labels, average='weighted')\n",
        "\n",
        "# Print the metrics\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1-score: {f1:.4f}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
